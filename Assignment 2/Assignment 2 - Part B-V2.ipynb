{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model to predict engagement with image labels (text) as predictors. Is this model better than using captions to predict the same? What if you used both image labels and captions to predict engagement? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "gv = pd.read_csv(\"gv_labels.csv\")\n",
    "insta = pd.read_csv(\"insta_withid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing captions(hashtags) and cleaning them to create strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Akhil\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Akhil\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_image</th>\n",
       "      <th>Engagement_score</th>\n",
       "      <th>photo</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags1</th>\n",
       "      <th>hashtags2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981399443030738687</td>\n",
       "      <td>-0.635760</td>\n",
       "      <td>1</td>\n",
       "      <td>['happypills', 'pills', 'pharma', 'bigpharma']</td>\n",
       "      <td>[happypills, pills, pharma, bigpharma]</td>\n",
       "      <td>happypills pills pharma bigpharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980599326570032905</td>\n",
       "      <td>-0.075393</td>\n",
       "      <td>1</td>\n",
       "      <td>['1', '2']</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980506709442276709</td>\n",
       "      <td>-0.381748</td>\n",
       "      <td>1</td>\n",
       "      <td>['FollowMe', 'Madagascar', 'Enoughness', 'natu...</td>\n",
       "      <td>[FollowMe, Madagascar, Enoughness, nature]</td>\n",
       "      <td>followme madagascar enoughness nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980429175895768953</td>\n",
       "      <td>1.064558</td>\n",
       "      <td>1</td>\n",
       "      <td>['snowstorm', 'penguin', 'antarctica']</td>\n",
       "      <td>[snowstorm, penguin, antarctica]</td>\n",
       "      <td>snowstorm penguin antarctica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980332447939109605</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>1</td>\n",
       "      <td>['whales', 'humpbackwhales', 'parenting', 'pla...</td>\n",
       "      <td>[whales, humpbackwhales, parenting, planetofth...</td>\n",
       "      <td>whales humpbackwhales parenting planetofthewhales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id_image  Engagement_score  photo  \\\n",
       "0  1981399443030738687         -0.635760      1   \n",
       "1  1980599326570032905         -0.075393      1   \n",
       "2  1980506709442276709         -0.381748      1   \n",
       "3  1980429175895768953          1.064558      1   \n",
       "4  1980332447939109605          0.036183      1   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0     ['happypills', 'pills', 'pharma', 'bigpharma']   \n",
       "1                                         ['1', '2']   \n",
       "2  ['FollowMe', 'Madagascar', 'Enoughness', 'natu...   \n",
       "3             ['snowstorm', 'penguin', 'antarctica']   \n",
       "4  ['whales', 'humpbackwhales', 'parenting', 'pla...   \n",
       "\n",
       "                                           hashtags1  \\\n",
       "0             [happypills, pills, pharma, bigpharma]   \n",
       "1                                             [1, 2]   \n",
       "2         [FollowMe, Madagascar, Enoughness, nature]   \n",
       "3                   [snowstorm, penguin, antarctica]   \n",
       "4  [whales, humpbackwhales, parenting, planetofth...   \n",
       "\n",
       "                                           hashtags2  \n",
       "0                  happypills pills pharma bigpharma  \n",
       "1                                                1 2  \n",
       "2              followme madagascar enoughness nature  \n",
       "3                       snowstorm penguin antarctica  \n",
       "4  whales humpbackwhales parenting planetofthewhales  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "insta1 = insta[['id_image','Engagement_score','photo','hashtags']]\n",
    "\n",
    "# Converting strings to list in hashtags\n",
    "insta1['hashtags1'] = insta1['hashtags'].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "# Concatenating the list of hashtags to be fed into count vectorizer\n",
    "insta1['hashtags2'] = insta1['hashtags1'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# converting to lower case\n",
    "insta1['hashtags2'] = insta1['hashtags2'].apply(lambda x: x.lower())\n",
    "\n",
    "insta1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction using hashtags as features\n",
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(insta1['hashtags2'])\n",
    "count_vect.get_feature_names()\n",
    "X_matrix= X_train_counts.todense()\n",
    "\n",
    "y = np.array(insta1['Engagement_score'])\n",
    "\n",
    "# Creating the train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_m, X_val_m, y_train_m, y_val_m = train_test_split(X_train_counts, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_insta = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "rf_insta.fit(X_train_m, y_train_m)\n",
    "predictions_rf = rf_insta.predict(X_val_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using random forest on instagram captions is: 0.53\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = np.sqrt(np.mean((predictions_rf - y_val_m)**2))\n",
    "print('RMSE using random forest on instagram captions is:', round(rmse_rf, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using XGB on instagram captions is: 0.52\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 700, \n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective':'reg:linear',\n",
    "    'learning_rate': 0.01   \n",
    "}\n",
    "\n",
    "model = XGBRegressor(**xgb_params).fit(X_train_m, y_train_m)\n",
    "\n",
    "preds_xgb = model.predict(X_val_m)\n",
    "\n",
    "\n",
    "rmse_xgb = np.sqrt(np.mean((preds_xgb - y_val_m)**2))\n",
    "print('RMSE using XGB on instagram captions is:', round(rmse_xgb, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using image labels obtained from Google cloud Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imageid</th>\n",
       "      <th>labels</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1887675048681946284</td>\n",
       "      <td>['Reflection', 'Water', 'Blue', 'Waterway', 'S...</td>\n",
       "      <td>[0.9603376388549805, 0.9512578248977661, 0.937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1887750972126714187</td>\n",
       "      <td>['Sport venue', 'Product', 'Stadium', 'Fan', '...</td>\n",
       "      <td>[0.9421510100364685, 0.9413959383964539, 0.921...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1887939394339128382</td>\n",
       "      <td>['Eyewear', 'Glasses', 'Cool', 'Nail', 'Hand',...</td>\n",
       "      <td>[0.9922423958778381, 0.9812176823616028, 0.893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1888007540646834631</td>\n",
       "      <td>['Hair', 'Face', 'Hairstyle', 'Forehead', 'Hea...</td>\n",
       "      <td>[0.9909557700157166, 0.9656747579574585, 0.960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1888083309374639933</td>\n",
       "      <td>['Transport', 'Green', 'Mode of transport', 'P...</td>\n",
       "      <td>[0.9205442667007446, 0.9068462252616882, 0.808...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              imageid  \\\n",
       "0           0  1887675048681946284   \n",
       "1           1  1887750972126714187   \n",
       "2           2  1887939394339128382   \n",
       "3           3  1888007540646834631   \n",
       "4           4  1888083309374639933   \n",
       "\n",
       "                                              labels  \\\n",
       "0  ['Reflection', 'Water', 'Blue', 'Waterway', 'S...   \n",
       "1  ['Sport venue', 'Product', 'Stadium', 'Fan', '...   \n",
       "2  ['Eyewear', 'Glasses', 'Cool', 'Nail', 'Hand',...   \n",
       "3  ['Hair', 'Face', 'Hairstyle', 'Forehead', 'Hea...   \n",
       "4  ['Transport', 'Green', 'Mode of transport', 'P...   \n",
       "\n",
       "                                              scores  \n",
       "0  [0.9603376388549805, 0.9512578248977661, 0.937...  \n",
       "1  [0.9421510100364685, 0.9413959383964539, 0.921...  \n",
       "2  [0.9922423958778381, 0.9812176823616028, 0.893...  \n",
       "3  [0.9909557700157166, 0.9656747579574585, 0.960...  \n",
       "4  [0.9205442667007446, 0.9068462252616882, 0.808...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Converting strings to list in hashtags\n",
    "gv['labels1'] = gv['labels'].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "# # Concatenating the list of hashtags to be fed into count vectorizer\n",
    "gv['labels2'] = gv['labels1'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# converting to lower case\n",
    "gv['labels2'] = gv['labels2'].apply(lambda x: x.lower())\n",
    "\n",
    "# # merging to get engagement scores\n",
    "gv1 = pd.merge(insta1,gv,how = 'inner',left_on ='id_image',right_on = 'imageid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_image</th>\n",
       "      <th>Engagement_score</th>\n",
       "      <th>photo</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags1</th>\n",
       "      <th>hashtags2</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imageid</th>\n",
       "      <th>labels</th>\n",
       "      <th>scores</th>\n",
       "      <th>labels1</th>\n",
       "      <th>labels2</th>\n",
       "      <th>final_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981399443030738687</td>\n",
       "      <td>-0.635760</td>\n",
       "      <td>1</td>\n",
       "      <td>['happypills', 'pills', 'pharma', 'bigpharma']</td>\n",
       "      <td>[happypills, pills, pharma, bigpharma]</td>\n",
       "      <td>happypills pills pharma bigpharma</td>\n",
       "      <td>1090</td>\n",
       "      <td>1981399443030738687</td>\n",
       "      <td>['Leisure', 'Party', 'Drink', 'Vacation', 'Sit...</td>\n",
       "      <td>[0.6388171315193176, 0.631462812423706, 0.6256...</td>\n",
       "      <td>[Leisure, Party, Drink, Vacation, Sitting, Fur...</td>\n",
       "      <td>leisure party drink vacation sitting furniture...</td>\n",
       "      <td>happypills pills pharma bigpharmaleisure party...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980599326570032905</td>\n",
       "      <td>-0.075393</td>\n",
       "      <td>1</td>\n",
       "      <td>['1', '2']</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1 2</td>\n",
       "      <td>1089</td>\n",
       "      <td>1980599326570032905</td>\n",
       "      <td>['Mountainous landforms', 'Mountain', 'Mountai...</td>\n",
       "      <td>[0.9923034310340881, 0.987432062625885, 0.9084...</td>\n",
       "      <td>[Mountainous landforms, Mountain, Mountain ran...</td>\n",
       "      <td>mountainous landforms mountain mountain range ...</td>\n",
       "      <td>1 2mountainous landforms mountain mountain ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980506709442276709</td>\n",
       "      <td>-0.381748</td>\n",
       "      <td>1</td>\n",
       "      <td>['FollowMe', 'Madagascar', 'Enoughness', 'natu...</td>\n",
       "      <td>[FollowMe, Madagascar, Enoughness, nature]</td>\n",
       "      <td>followme madagascar enoughness nature</td>\n",
       "      <td>1088</td>\n",
       "      <td>1980506709442276709</td>\n",
       "      <td>['Tree', 'Adaptation', 'Working animal', 'Chil...</td>\n",
       "      <td>[0.9000945091247559, 0.840880811214447, 0.7956...</td>\n",
       "      <td>[Tree, Adaptation, Working animal, Child, Gras...</td>\n",
       "      <td>tree adaptation working animal child grass pla...</td>\n",
       "      <td>followme madagascar enoughness naturetree adap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980429175895768953</td>\n",
       "      <td>1.064558</td>\n",
       "      <td>1</td>\n",
       "      <td>['snowstorm', 'penguin', 'antarctica']</td>\n",
       "      <td>[snowstorm, penguin, antarctica]</td>\n",
       "      <td>snowstorm penguin antarctica</td>\n",
       "      <td>1087</td>\n",
       "      <td>1980429175895768953</td>\n",
       "      <td>['Bird', 'Penguin', 'Vertebrate', 'Flightless ...</td>\n",
       "      <td>[0.9960000514984131, 0.9883484244346619, 0.985...</td>\n",
       "      <td>[Bird, Penguin, Vertebrate, Flightless bird, B...</td>\n",
       "      <td>bird penguin vertebrate flightless bird beak a...</td>\n",
       "      <td>snowstorm penguin antarcticabird penguin verte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980332447939109605</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>1</td>\n",
       "      <td>['whales', 'humpbackwhales', 'parenting', 'pla...</td>\n",
       "      <td>[whales, humpbackwhales, parenting, planetofth...</td>\n",
       "      <td>whales humpbackwhales parenting planetofthewhales</td>\n",
       "      <td>1086</td>\n",
       "      <td>1980332447939109605</td>\n",
       "      <td>['Marine mammal', 'Marine biology', 'Cetacea',...</td>\n",
       "      <td>[0.945663571357727, 0.9357404112815857, 0.9342...</td>\n",
       "      <td>[Marine mammal, Marine biology, Cetacea, Under...</td>\n",
       "      <td>marine mammal marine biology cetacea underwate...</td>\n",
       "      <td>whales humpbackwhales parenting planetofthewha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id_image  Engagement_score  photo  \\\n",
       "0  1981399443030738687         -0.635760      1   \n",
       "1  1980599326570032905         -0.075393      1   \n",
       "2  1980506709442276709         -0.381748      1   \n",
       "3  1980429175895768953          1.064558      1   \n",
       "4  1980332447939109605          0.036183      1   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0     ['happypills', 'pills', 'pharma', 'bigpharma']   \n",
       "1                                         ['1', '2']   \n",
       "2  ['FollowMe', 'Madagascar', 'Enoughness', 'natu...   \n",
       "3             ['snowstorm', 'penguin', 'antarctica']   \n",
       "4  ['whales', 'humpbackwhales', 'parenting', 'pla...   \n",
       "\n",
       "                                           hashtags1  \\\n",
       "0             [happypills, pills, pharma, bigpharma]   \n",
       "1                                             [1, 2]   \n",
       "2         [FollowMe, Madagascar, Enoughness, nature]   \n",
       "3                   [snowstorm, penguin, antarctica]   \n",
       "4  [whales, humpbackwhales, parenting, planetofth...   \n",
       "\n",
       "                                           hashtags2  Unnamed: 0  \\\n",
       "0                  happypills pills pharma bigpharma        1090   \n",
       "1                                                1 2        1089   \n",
       "2              followme madagascar enoughness nature        1088   \n",
       "3                       snowstorm penguin antarctica        1087   \n",
       "4  whales humpbackwhales parenting planetofthewhales        1086   \n",
       "\n",
       "               imageid                                             labels  \\\n",
       "0  1981399443030738687  ['Leisure', 'Party', 'Drink', 'Vacation', 'Sit...   \n",
       "1  1980599326570032905  ['Mountainous landforms', 'Mountain', 'Mountai...   \n",
       "2  1980506709442276709  ['Tree', 'Adaptation', 'Working animal', 'Chil...   \n",
       "3  1980429175895768953  ['Bird', 'Penguin', 'Vertebrate', 'Flightless ...   \n",
       "4  1980332447939109605  ['Marine mammal', 'Marine biology', 'Cetacea',...   \n",
       "\n",
       "                                              scores  \\\n",
       "0  [0.6388171315193176, 0.631462812423706, 0.6256...   \n",
       "1  [0.9923034310340881, 0.987432062625885, 0.9084...   \n",
       "2  [0.9000945091247559, 0.840880811214447, 0.7956...   \n",
       "3  [0.9960000514984131, 0.9883484244346619, 0.985...   \n",
       "4  [0.945663571357727, 0.9357404112815857, 0.9342...   \n",
       "\n",
       "                                             labels1  \\\n",
       "0  [Leisure, Party, Drink, Vacation, Sitting, Fur...   \n",
       "1  [Mountainous landforms, Mountain, Mountain ran...   \n",
       "2  [Tree, Adaptation, Working animal, Child, Gras...   \n",
       "3  [Bird, Penguin, Vertebrate, Flightless bird, B...   \n",
       "4  [Marine mammal, Marine biology, Cetacea, Under...   \n",
       "\n",
       "                                             labels2  \\\n",
       "0  leisure party drink vacation sitting furniture...   \n",
       "1  mountainous landforms mountain mountain range ...   \n",
       "2  tree adaptation working animal child grass pla...   \n",
       "3  bird penguin vertebrate flightless bird beak a...   \n",
       "4  marine mammal marine biology cetacea underwate...   \n",
       "\n",
       "                                        final_vector  \n",
       "0  happypills pills pharma bigpharmaleisure party...  \n",
       "1  1 2mountainous landforms mountain mountain ran...  \n",
       "2  followme madagascar enoughness naturetree adap...  \n",
       "3  snowstorm penguin antarcticabird penguin verte...  \n",
       "4  whales humpbackwhales parenting planetofthewha...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(gv1['labels2'])\n",
    "count_vect.get_feature_names()\n",
    "X_matrix= X_train_counts.todense()\n",
    "\n",
    "y = np.array(gv1['Engagement_score'])\n",
    "\n",
    "# Creating the train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_m, X_val_m, y_train_m, y_val_m = train_test_split(X_train_counts, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_insta = RandomForestRegressor(n_estimators = 700, random_state = 42)\n",
    "rf_insta.fit(X_train_m, y_train_m)\n",
    "predictions_rf = rf_insta.predict(X_val_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame(X_matrix,columns = count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using random forest on instagram captions is: 1.07\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = np.sqrt(np.mean((predictions_rf - y_val_m)**2))\n",
    "print('RMSE using random forest on instagram captions is:', round(rmse_rf, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using XGB on instagram captions is: 1.06\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 700, \n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective':'reg:linear',\n",
    "    'learning_rate': 0.01   \n",
    "}\n",
    "\n",
    "model = XGBRegressor(**xgb_params).fit(X_train_m, y_train_m)\n",
    "\n",
    "preds_xgb = model.predict(X_val_m)\n",
    "\n",
    "\n",
    "rmse_xgb = np.sqrt(np.mean((preds_xgb - y_val_m)**2))\n",
    "print('RMSE using XGB on instagram captions is:', round(rmse_xgb, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using both captions(hashtags) and image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv1['final_vector'] = gv1.apply(lambda row : row['hashtags2'] + row['labels2'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(gv1['final_vector'])\n",
    "count_vect.get_feature_names()\n",
    "X_matrix= X_train_counts.todense()\n",
    "\n",
    "y = np.array(gv1['Engagement_score'])\n",
    "\n",
    "# Creating the train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_m, X_val_m, y_train_m, y_val_m = train_test_split(X_train_counts, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_insta = RandomForestRegressor(n_estimators = 700, random_state = 42)\n",
    "rf_insta.fit(X_train_m, y_train_m)\n",
    "predictions_rf = rf_insta.predict(X_val_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using random forest on instagram captions is: 1.09\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = np.sqrt(np.mean((predictions_rf - y_val_m)**2))\n",
    "print('RMSE using random forest on instagram captions is:', round(rmse_rf, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using XGB on instagram captions is: 1.06\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 700, \n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'objective':'reg:linear',\n",
    "    'learning_rate': 0.01   \n",
    "}\n",
    "\n",
    "model = XGBRegressor(**xgb_params).fit(X_train_m, y_train_m)\n",
    "\n",
    "preds_xgb = model.predict(X_val_m)\n",
    "\n",
    "\n",
    "rmse_xgb = np.sqrt(np.mean((preds_xgb - y_val_m)**2))\n",
    "print('RMSE using XGB on instagram captions is:', round(rmse_xgb, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion   \n",
    "In our case, we can see that hashtags contribute to a smaller rmse in comparison to using just image labels or a combination of hashtags and labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
